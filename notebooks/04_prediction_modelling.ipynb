{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f1b61a2f",
      "metadata": {},
      "source": [
        "# EV RUL Prediction: XGBoost & Random Forest\n",
        "\n",
        "This notebook trains XGBoostRegressor and RandomForestRegressor models to predict Remaining Useful Life (RUL) for EV components. We compare their performance using RMSE and MAE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47d9ebba",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69908b84",
      "metadata": {},
      "source": [
        "## Load and Prepare Data\n",
        "\n",
        "Load the preprocessed feature set and split into training and test sets for RUL prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c360ef9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load preprocessed features (after feature engineering)\n",
        "data = pd.read_csv('../data/features/features_for_modeling.csv')\n",
        "\n",
        "# We will predict the 'overall_health_score' as a proxy for RUL.\n",
        "target_variable = 'overall_health_score'\n",
        "\n",
        "# Prepare features (X) and target (y)\n",
        "# Ensure the target variable itself is not included in the features\n",
        "X = data.drop(columns=[target_variable]) \n",
        "y = data[target_variable]\n",
        "\n",
        "# Ensure all feature columns are numeric before training\n",
        "X = X.select_dtypes(include=np.number)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Models will be trained to predict: '{target_variable}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b731f59",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "for col in cols:\n",
        "    print(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7a9669d",
      "metadata": {},
      "source": [
        "## Train XGBoostRegressor\n",
        "\n",
        "Train an XGBoostRegressor model on the training data for RUL prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d9825a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train XGBoostRegressor\n",
        "xgb_model = XGBRegressor(random_state=42, n_jobs=-1)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "xgb_pred = xgb_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55d1a724",
      "metadata": {},
      "source": [
        "## Train RandomForestRegressor\n",
        "\n",
        "Train a RandomForestRegressor model on the training data for RUL prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeaa3b1e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train RandomForestRegressor\n",
        "rf_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "rf_pred = rf_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a34299fc",
      "metadata": {},
      "source": [
        "## Evaluate Model Performance\n",
        "\n",
        "Evaluate both models using RMSE and MAE on the test set, and compare their results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7b6f39f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate XGBoostRegressor\n",
        "xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
        "xgb_mae = mean_absolute_error(y_test, xgb_pred)\n",
        "\n",
        "# Evaluate RandomForestRegressor\n",
        "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
        "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
        "\n",
        "print(f\"XGBoostRegressor RMSE: {xgb_rmse:.2f}, MAE: {xgb_mae:.2f}\")\n",
        "print(f\"RandomForestRegressor RMSE: {rf_rmse:.2f}, MAE: {rf_mae:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4acdd12",
      "metadata": {},
      "source": [
        "- RMSE  (Root Mean Squared Error) measures the square root of the average squared differences between predicted and actual values. It penalizes larger errors more heavily and is sensitive to outliers.\n",
        "- MAE (Mean Absolute Error) measures the average absolute differences between predicted and actual values. It treats all errors equally and is more robust to outliers.\n",
        "- We use RMSE and MAE to quantify how well the model predicts the Remaining Useful Life (RUL). Lower values mean better predictions. Using both gives a more complete picture of model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbea917a",
      "metadata": {},
      "source": [
        "Testing if we used raw data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fce48d30",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load raw data (before feature engineering)\n",
        "raw_data = pd.read_csv('../archive/EV_Predictive_Maintenance_Dataset_15min.csv')\n",
        "\n",
        "# Convert Timestamp to datetime if needed\n",
        "raw_data['Timestamp'] = pd.to_datetime(raw_data['Timestamp'])\n",
        "\n",
        "# Prepare features and target from raw data\n",
        "X_raw = raw_data.drop(['RUL', 'Timestamp'], axis=1)\n",
        "y_raw = raw_data['RUL']\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y_raw, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train XGBoostRegressor on raw features\n",
        "xgb_model_raw = XGBRegressor(random_state=42, n_jobs=-1)\n",
        "xgb_model_raw.fit(X_train_raw, y_train_raw)\n",
        "xgb_pred_raw = xgb_model_raw.predict(X_test_raw)\n",
        "\n",
        "# Train RandomForestRegressor on raw features\n",
        "rf_model_raw = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "rf_model_raw.fit(X_train_raw, y_train_raw)\n",
        "rf_pred_raw = rf_model_raw.predict(X_test_raw)\n",
        "\n",
        "# Evaluate models on raw features\n",
        "xgb_rmse_raw = np.sqrt(mean_squared_error(y_test_raw, xgb_pred_raw))\n",
        "xgb_mae_raw = mean_absolute_error(y_test_raw, xgb_pred_raw)\n",
        "rf_rmse_raw = np.sqrt(mean_squared_error(y_test_raw, rf_pred_raw))\n",
        "rf_mae_raw = mean_absolute_error(y_test_raw, rf_pred_raw)\n",
        "\n",
        "print(f\"XGBoostRegressor (raw) RMSE: {xgb_rmse_raw:.2f}, MAE: {xgb_mae_raw:.2f}\")\n",
        "print(f\"RandomForestRegressor (raw) RMSE: {rf_rmse_raw:.2f}, MAE: {rf_mae_raw:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}